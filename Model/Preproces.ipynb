{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# E-Mail Spam Classification\n",
    "## YZV 311E Term Project\n",
    "\n",
    "Abdullah Bilici, 150200330\n",
    "\n",
    "Bora Boyacıoğlu, 150200310"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import the necessary libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import spacy\n",
    "import string\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the Data\n",
    "\n",
    "Load the CSV data to a Pandas DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "mails = pd.read_csv(\"../Data/emails.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sice the data is too large, using a ~1/20 batch would be easier for test purposes.\n",
    "mails_full = mails.copy()\n",
    "mails = mails.iloc[:250]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text Preprocessing\n",
    "\n",
    "Using an English NLP model, tokenise the sentences for each mail. Then, apply some rules to make the data workable. These include:\n",
    "\n",
    "* Tokenisation\n",
    "1. Lowercasing\n",
    "2. Stop word removal\n",
    "3. Special character removal\n",
    "4. Lemmatisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the language model\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "# Get the stop words and punctuations\n",
    "stop_words = set(nlp.Defaults.stop_words)\n",
    "punctuations = set(string.punctuation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a function for tokenising and preprocessing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenise_sentence(sentence):\n",
    "    # Error handling for non-string inputs\n",
    "    if not isinstance(sentence, str):\n",
    "        return []\n",
    "    \n",
    "    # Tokenise the sentence\n",
    "    tokenised = nlp(sentence)\n",
    "    \n",
    "    # Lowercase and lemmatise the words\n",
    "    tokens = [token.lemma_.lower().strip() if token.pos_ != \"PRON\" else token.lower_ for token in tokenised]\n",
    "    \n",
    "    # Remove stop words and special characters\n",
    "    tokens = [token for token in tokens if token not in stop_words and token not in punctuations]\n",
    "    \n",
    "    # Remove empty tokens\n",
    "    tokens = [token for token in tokens if token != '']\n",
    "    \n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply tokenisation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "mails['tokenised_text'] = mails['text'].apply(tokenise_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [subject, naturally, irresistible, corporate, ...\n",
       "1    [subject, stock, trading, gunslinger, fanny, m...\n",
       "2    [subject, unbelievable, new, home, easy, m, wa...\n",
       "3    [subject, 4, color, printing, special, request...\n",
       "4    [subject, money, software, cd, software, compa...\n",
       "Name: tokenised_text, dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mails['tokenised_text'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['subject',\n",
       " 'naturally',\n",
       " 'irresistible',\n",
       " 'corporate',\n",
       " 'identity',\n",
       " 'lt',\n",
       " 'hard',\n",
       " 'recollect',\n",
       " 'company',\n",
       " 'market',\n",
       " 'suqgestion',\n",
       " 'information',\n",
       " 'isoverwhelminq',\n",
       " 'good',\n",
       " 'catchy',\n",
       " 'logo',\n",
       " 'stylish',\n",
       " 'statlonery',\n",
       " 'outstanding',\n",
       " 'website',\n",
       " 'task',\n",
       " 'easy',\n",
       " 'promise',\n",
       " 'havinq',\n",
       " 'order',\n",
       " 'iogo',\n",
       " 'company',\n",
       " 'automaticaily',\n",
       " 'world',\n",
       " 'ieader',\n",
       " 'isguite',\n",
       " 'ciear',\n",
       " 'good',\n",
       " 'product',\n",
       " 'effective',\n",
       " 'business',\n",
       " 'organization',\n",
       " 'practicable',\n",
       " 'aim',\n",
       " 'hotat',\n",
       " 'nowadays',\n",
       " 'market',\n",
       " 'promise',\n",
       " 'marketing',\n",
       " 'effort',\n",
       " 'effective',\n",
       " 'list',\n",
       " 'clear',\n",
       " 'benefit',\n",
       " 'creativeness',\n",
       " 'hand',\n",
       " 'original',\n",
       " 'logo',\n",
       " 'specially',\n",
       " 'reflect',\n",
       " 'distinctive',\n",
       " 'company',\n",
       " 'image',\n",
       " 'convenience',\n",
       " 'logo',\n",
       " 'stationery',\n",
       " 'provide',\n",
       " 'format',\n",
       " 'easy',\n",
       " 'use',\n",
       " 'content',\n",
       " 'management',\n",
       " 'system',\n",
       " 'letsyou',\n",
       " 'change',\n",
       " 'website',\n",
       " 'content',\n",
       " 'structure',\n",
       " 'promptness',\n",
       " 'logo',\n",
       " 'draft',\n",
       " 'business',\n",
       " 'day',\n",
       " 'affordability',\n",
       " 'marketing',\n",
       " 'break',\n",
       " 'shouldn',\n",
       " 't',\n",
       " 'gap',\n",
       " 'budget',\n",
       " '100',\n",
       " 'satisfaction',\n",
       " 'guarantee',\n",
       " 'provide',\n",
       " 'unlimited',\n",
       " 'change',\n",
       " 'extra',\n",
       " 'fee',\n",
       " 'surethat',\n",
       " 'love',\n",
       " 'result',\n",
       " 'collaboration',\n",
       " 'look',\n",
       " 'portfolio',\n",
       " 'interested']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mails.iloc[0]['tokenised_text']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
