\documentclass[conference]{IEEEtran}
% \IEEEoverridecommandlockouts
% The preceding line is only needed to identify funding in the first footnote. If that is unneeded, please comment it out.
\usepackage{cite}
\usepackage{amsmath,amssymb,amsfonts}
\usepackage{algorithmic}
\usepackage{graphicx}
\usepackage{textcomp}
\usepackage{xcolor}
\usepackage{hyperref}
\usepackage{tabularx}
\usepackage{pgfgantt}
\def\BibTeX{{\rm B\kern-.05em{\sc i\kern-.025em b}\kern-.08em
    T\kern-.1667em\lower.7ex\hbox{E}\kern-.125emX}}
\begin{document}

\title{E-Mail Spam Classification\\
{\Large YZV 311E Term Project Proposal}
}

\author{\IEEEauthorblockN{Abdullah Bilici}
\IEEEauthorblockA{\textit{Artificial Intelligence \& Data Engineering} \\
\textit{Istanbul Technical University}\\
bilicia@itu.edu.tr\\ 150200330}
\and
\IEEEauthorblockN{Bora Boyacıoğlu}
\IEEEauthorblockA{\textit{Artificial Intelligence \& Data Engineering} \\
\textit{Istanbul Technical University}\\
boyacioglu20@itu.edu.tr\\ 150200310}
}

\maketitle

\begin{abstract}
This documents is the project proposal for the YZV 311E Data Mining course term project. It is about an E-Mail classification model using techniques like Natural Language Processing. It is being held by Abdullah Bilici and Bora Boyacıoğlu, Istanbul Technical University. Team number is 8.
\end{abstract}

\begin{IEEEkeywords}
email, spam, classification, natural language processing
\end{IEEEkeywords}

\section{Introduction}
In this project, we will generate a classification to classify spam E-Mails.

As the companies do not care about data security and sell people's data to other companies, frauds use this data to send spam E-Mails. These kinds of E-Mails sometimes look very realistic and most of the people think of it as a legitimate E-Mail. They may want people to enter their passwords, share their credit cards, and so on. However, most of the E-Mails are actually not very realistic. Though, sometimes people fall for their traps when they tell the people that they won money.

Therefore, classifying these E-Mails as spam is a critical task for E-Mail companies. There are some easy signs indicating that the E-Mail is spam, but there are also very professional spams. It is hard to separate them from legitimate ones.

One way to do this classification is actually to create a model using already human-classified data and look up the new E-Mails using this model. In the next section, dataset will be introduced.

Our team consists of two members: Abdullah Bilici and Bora Boyacıoğlu. We are both from Istanbul Technical University, Artificial Intelligence and Data Engineering department.

\section{Dataset}
We are going to be using a dataset from Kaggle. It is called \href{https://www.kaggle.com/code/harshsinha1234/email-spam-classification-nlp/input}{\textbf{Email Spam Classification} (Harsh Sinha, 2020)} \cite{dataset} and contains basic E-Mail messages alongside a category \textit{(spam/ham)}. Therefore, it only has two features: Text \textit{(str)} and Spam \textit{(bool)}. It contains 5728 values and has \textit{8.95 MB} size. It uses \textit{CSV} format.

All of the rows have a value \textbf{1} or \textbf{0} indicating whether the given E-Mail is spam or legitimate, and the message (content) of the E-Mail. Randomly selected six rows of the dataset are given in Table \ref{table: dataset preview}.

% Example from the dataset
\begin{table}[h]
    \centering
    \caption{E-Mail Classification Dataset}
    \begin{tabularx}{\columnwidth}{|X|c|}
        \hline
        \textbf{Text} & \textbf{Spam} \\ [0.5ex] 
        \hline\hline
        subject : naturally irresistible your corporate identity  lt is really hard to recollect a company : the  market is full of suqgestions\dots & True \\
        \hline
        subject : greatly improve your stamina  the longz system , both the capsules and the free instructional manual , give  you the\dots & True \\
        \hline
        subject : new basis report  bhavna :  the basis report has been updated to cover 2000 prices . it is called  basisnw 7 . xls and\dots & False \\
        \hline
        subject : localized software , all languages available .  hello , we would like to offer localized software versions qerman , \dots & True \\
        \hline
        subject : approval for reviewer  krishnarao , pinnamaneni v has suggested reviewers and submitted them for your  approval . \dots & False \\
        \hline
        subject : research prc next steps  the pep system is no longer available to accept feedback from reviewers . if  necessary , \dots & False \\
        \hline
    \end{tabularx}
    \label{table: dataset preview}
\end{table}

\section{Methodology}
In this section, we outline a high-level methodology for building our email spam classifier. We'll provide an overview of the essential steps in our approach.

\subsection{Text Preprocessing}
To prepare the data for modeling, we will perform text preprocessing. This includes standardization tasks like removing special characters, converting text to lowercase, and tokenization. Additionally, we need to solve the issue of class imbalance.

\begin{itemize}
    \item \textbf{Tokenization:} Splitting the text into words. We may use libraries like NLTK or spaCy for this.
    \item \textbf{Lowercasing:} Converting the text to only use lowercase characters for consistency.
    \item \textbf{Removing Special Characters:} Useing Regex to eliminate unnecessary characters (punctuations, tags).
    \item \textbf{Stopword Removal:} Eliminating words like and, the, in that seem extra.
    \item \textbf{Lemmatization or Stemming:} Reducing words to their base versions (\textit{running} will be \textit{run}).
\end{itemize}

\subsection{Feature Engineering}
In feature engineering, we will transform the preprocessed text data into a numerical format suitable for modeling. We will create feature vectors or representations that capture essential information from the emails.

\begin{itemize}
    \item \textbf{TF-IDF (Term Frequency-Inverse Document Frequency):} Converting the text into numerical vectors using TF-IDF to show the importance of words in the texts.
    \item \textbf{Word Embeddings (e.g., Word2Vec, GloVe):} Createing dense vector representations of words and gather them to represent documents.
    \item \textbf{N-grams:} We may consider n-grams (sequences of n words) to capture context and phrases in the text.
    \item \textbf{Topic Modeling (e.g., LDA, NMF):} Extracting subjects from the emails and using their distributions as features.
    \item \textbf{Sentiment Analysis:} Analyzing the sentiment of the text as a feature.
\end{itemize}

\subsection{Data Splitting}
We will split our dataset into a training set and a testing set. This division is essential for assessing the performance of our classifier.

\begin{itemize}
    \item \textbf{Train-Test Split:} Splitting the dataset into a training set (70\% to 80\% of the data) and a testing set (20\% to 30\%) to evaluate the model's performance.
    \item \textbf{Cross-Validation:} We may consider k-fold cross validation for more robust model evaluation.
\end{itemize}

\subsection{Model Selection and Training}
We will select and train a machine learning model suitable for text classification. The training process involves teaching the model to distinguish between spam and ham emails.

\begin{itemize}
    \item Naive Bayes Classifier
    \item Support Vector Machines (SVM)
    \item Logistic Regression
    \item Random Forest
\end{itemize}

\section{Evaluation Methods}
In our evaluation process, we will assess the success of our email spam classification project using the following steps:

\subsection{Performance Metrics} We will employ standard evaluation metrics such as accuracy, precision, recall, F1-score, and AUC-ROC to measure the effectiveness of our models.

\subsection{Algorithm Selection} We will experiment with different algorithms. We consider the following algorithms for email classification:

\begin{itemize}
    \item Naive Bayes
    \item Logistic Regression
    \item Random Forest
    \item Support Vector Machines (SVM)
\end{itemize}

Our project's success will be judged based on the ability of the chosen algorithm to outperform the baseline model and achieve high performance metrics. The goal is to develop an effective and accurate email spam classification solution.

\section{GitHub Repository}
You can access our Github repository using this link: \href{https://github.com/abdullahbilici/E-mail-Spam-Classification}{https://github.com/abdullahbilici/E-mail-Spam-Classification}.

We have already sent invitations to teaching assistants. So, they will be able to see our progress. We also wanted to share the Personal Access Token for our repository: {\tiny github\_pat\_11BCDFDAQ0sVeeT5ksCRNu\_IuGbWtv4t64ThXyX9ZiN8IbbagaxK75q4DJ2I4w7vgIHREIEV5RtwbOmtAA}

We are going to be updating the file \verb|Progress.txt| in order to show our progress.

\section{Time Plan \& Distribution of Work}

\begin{table}[h]
    \centering
    \caption{Timeline and Work Distribution}
    \begin{ganttchart}[
        hgrid,
        vgrid,
        x unit=0.5cm,
        y unit title=0.5cm,
        y unit chart=0.6cm,
        title height=1,
        title/.style={fill=gray!30},
        title label font=\footnotesize,
        group/.append style={draw=black, fill=yellow!30},
        milestone/.append style={fill=red},
        progress label text={},
        group right shift=0,
        group top shift=0,
        group height=0.4,
        bar height=0.7,
        bar label font=\tiny,
        group peaks height=0.2,
        ]{1}{10} % Adjust the range according to your project duration.
    
        \gantttitle{Week}{10} \\
        \gantttitlelist{1,...,10}{1} \\
    
        % Abdullah
        \ganttgroup[group/.append style={fill=blue}]{Abdullah}{1}{10} \\
        \ganttbar[bar/.append style={fill=blue}]{Task A}{1}{3} \\
        \ganttbar[bar/.append style={fill=blue}]{Task B}{4}{7} \\
        \ganttbar[bar/.append style={fill=blue}]{Task C}{8}{10} \\
    
        % Bora
        \ganttgroup[group/.append style={fill=green}]{Bora}{1}{10} \\
        \ganttbar[bar/.append style={fill=green}]{Task D}{1}{2} \\
        \ganttbar[bar/.append style={fill=green}]{Task E}{3}{5} \\
        \ganttbar[bar/.append style={fill=green}]{Task F}{6}{10} \\
    
        % Common Tasks
        \ganttgroup[group/.append style={fill=orange}]{Common}{1}{10} \\
        \ganttbar[bar/.append style={fill=orange}]{Task G}{1}{6} \\
        \ganttbar[bar/.append style={fill=orange}]{Task H}{7}{10} \\
    \end{ganttchart}
    \label{table: timeline}
\end{table}

\textit{In this section, create a timeline or Gantt chart to outline the project’s schedule. Define key milestones and deadlines, including dates for data collection, preprocessing, model development, and testing. Additionally, specify how the work will be distributed among the team members. Describe the roles and responsibilities of each team member, emphasizing their individual contributions to the project’s success. Each team member should describe his/her subproject by indicating his/her contribution to solve the problem.}

\section{Conclusion}
\textit{Summarize the main points of your proposal, highlighting the importance of your project and the potential impact it could have. Reiterate the problem, objectives, and your plan for addressing it. End with a clear call to action, emphasizing the significance of the project for the intended audience.}

\begin{thebibliography}{00}
\bibitem{dataset} Harsh Sinha, Email Spam Classification, 2020, Kaggle\\{\tiny\href{https://www.kaggle.com/code/harshsinha1234/email-spam-classification-nlp/input}{https://www.kaggle.com/code/harshsinha1234/email-spam-classification-nlp/input}}
\end{thebibliography}

\end{document}